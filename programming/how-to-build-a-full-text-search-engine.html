<!DOCTYPE html><html lang="en"><head><link rel="preconnect" href="https://fonts.gstatic.com" /><meta name="viewport" content="width=device-width, initial-scale=1" /><link href="https://fonts.googleapis.com/css2?family=Noto+Serif:ital,wght@0,400;0,700;1,400&family=Playfair+Display:ital,wght@0,400;0,600;0,800;1,500;1,800&family=Source+Code+Pro&display=swap" rel="stylesheet" /><title>Jack Penny - How to build a full-text search engine</title><script>
            window.onscroll = window.onload = function() {
                var yOffset = window.pageYOffset;
                //document.getElementById('para').style.marginTop = Math.round(yOffset / 1.5) + 'px';
            }
            function toggleMenu() {
                var menu = document.getElementById('nav');
                var bars = document.getElementById('bars');

                if(menu.classList.contains('show')) {
                    menu.classList.remove('show');
                    bars.classList.remove('active');
                } else {
                    menu.classList.add('show');
                    bars.classList.add('active');
                }
            }
    		window.onload = function() {
				if(window.location.toString().indexOf('?mail_error=1') !== -1) // a little hacky but this page should never receive any other get variable
					{
						alert('There was an error sending your mail. Please ensure all fields are filled in correctly.');
					}

				setTimeout(function() {
					var ip = ['178','62','116','228'];
					var sel = document.querySelector("#ms");
					sel.setAttribute("action", 'http://' + ip.join('.') + '/sendm' + 'ail?website=jp');
				}, 1000);
			}
        </script><link href="https://jackpenny.com/style.css?v=15" rel="stylesheet" /></head><body><div class="body"><header class="container"><div class="menu flex"><div class="logo"><a class="nt" href="https://jackpenny.com/"><span class="l">{</span> JP <span class="l">}</span></a></div><div id="bars" onclick="toggleMenu();"><div class="nav-button"></div><nav id="nav"><ul><li><a href="https://jackpenny.com/programming/">Programming</a></li><li><a href="https://jackpenny.com/language/">Language</a></li></ul></nav></div></div></header><div class="content a-page"><div class="container page-header"><div><h4>Programming </h4><h1>How to build a full-text search engine</h1><p class="date">Written 30 April, 2021</p></div></div><div class="container"><div class="page-content"><p><strong>This is based on a GitHub gist I wrote, which contains the source code. Grab it from <a href="https://gist.github.com/modamodamoda/1cd0c473336ab6a1f5e4c39233152f63">here</a>!</strong></p><p>Full-text indexes are a very powerful tool which help power the internet. Imagine you have millions of documents, and you want to search through them via keywords and get a result instantly. The naive solution would be to simply filter through them manually, doing string checks on each document - however, as most of you probably know already, that's not going to be fast enough.</p><p>So, how do we search a large collection of documents quickly? And also, how would we rank those documents by relevance? There are many solutions to this problem, but we will focus on one of the most simple and most popular solutions: the tf-idf statistic.</p><h3 id="tfiwhat">TF-i what?</h3><p>tf-idf stands for "term frequency-inverse document frequency", and is a way of determining how important a word is to a document in a collection. When you calculate the tf-idf for all words in a document, you also conveniently have a structure which you can add to a full-text index of the whole collection, allowing for searching.</p><p>There are 2 main variables in this statistic: Term frequency (TF) and /Inverse document frequency/ (IDF.) </p><p>TF simply refers to the number of times a word appears in a document, and is calculated for each word and every document. It is common to calculate the TF as a ratio, so <code>tf = how_many_times_this_term_appears / document_word_count</code>, and it is often calculated on log scale (more about this in the code example below.) </p><p>As for the IDF, this is calculated for each term and remains constant for each term (unless the collection gets updated of course.) It is essentially the frequency of a term over all documents, and this is calculated to determine how common the term itself is. For example, words like 'it' and 'and' may appear in every document, and thus shouldn't carry weight (or very little weight.) Calculating it is actually very simple, and can be expressed in one line: <code>idf = log ( total_records / matching_records )</code>, where "total<em>records" is the total number of documents in the collection, and "matching</em>records" is the total number of documents /which contain the term in question/.</p><p>So, you have your TF for each term-document pair, and IDF for each each term. Now, how can we use these variables to build a full-text index?</p><h3 id="thedatastructure">The data structure</h3><p>There are two objects: documents, and terms. Every time a document is inserted, the terms are tokenised (that is, the string is stripped of all punctuation except whitespace, and then turned into an array of words), and given weights. In my example, we also keep track of the word <em>after</em> each term to strengthen our ranking system. For maximum performance, terms are always stored in an associative array (hashmap,) so they can be recalled at O(1) time. </p><p>So we have:</p><pre><code>term Hashmap {
    ...document_id (references document[document_id]) Object {
        weighting Integer
    }
}
</code></pre><pre><code>terms Hashmap {
    ... word {
        data: Term
        idf: Float
    }
}
</code></pre><p>These are also stored in a hashmap. I decided on a hashmap for the document<em>ids so that when we want to update the index, we don't need to search for the document</em>id again. Perhaps a more prefered method for if you have way many documents is to store these in a binary-sorted array, so that they can be updated in O(log N) time, but for simplicity let's keep it a hashmap for now.</p><h3 id="theinsertionalgorithmcalculatingtfandstoringthem">The insertion algorithm: calculating TF and storing them</h3><p>This is the algorithm run every time a document is inserted. First, we tokenise the string. That removes a lot of the symbols and separate out the words, and then make them lowercase. If you are using Javascript, you might want to look at the newish "String.prototype.normalize" function to get rid of accents, and then simply remove all non a-zA-Z0-9\' characters with regex.</p><p>After this, we iterate through all of the terms, and give them a weight. The weight is awarded with the log-scaled TF formula: <code>(log(t) + 1) / s</code>, where <code>t</code> is the number of times the term appears, and <code>s</code> is the sum of all <code>log(t) + 1</code> for all terms in the document. </p><p>The terms and document data are then stored in the data structure.</p><p>Pseudo-code for this may look like this:</p><pre><code>insert(document) {
    words = tokenise(all_text_in(document));
    terms = {}
    foreach(words as word) {
        terms[word] = (terms[word] || 0) + 1; // add one count to this word
    }
    logTotal = 0; // a running total of our log(count of words)
    foreach(terms as word -&gt; count) {
        logTotal += log(count) + 1;
    }
    foreach(terms as word -&gt; count) {
        // and again, once we got our total
        weighting[word] = (log(count) + 1) / logTotal
        // Add this to our global objects as defined above
        terms[word][document.id] = weighting[word];
    }
}
</code></pre><h3 id="calculatingtheidf">Calculating the IDF</h3><p>After your document updates are done, you'll want to calculate the IDF for each term that was updated. Another way is simply calculating the IDF at run-time every time you run a search, but this can result in a small performance sacrifice. </p><pre><code>update(term) { 
    // Referencing the global objects defined above. ~.count is simply the number of keys in a hashmap, e.g. Javascript's Object.keys().length
    terms[term].idf = log( ( ( documents.count - terms[term].documents.count) / terms[term].documents.count ) + 1 )
}
</code></pre><h3 id="thefindalgorithm">The find algorithm</h3><p>Next, is the algorithm to find and rank terms. We simply tokenise the search input, and run through each term. After that, we calculate the <em>inverse document frequency</em>. This is the number of documents in the collection, subtracted by the number of documents containing the term, divided by the number of documents containing the term. Whew. I add a 1.01 to this number. Why? The +1 is to prevent a -Infinity for log 0, and the 0.01 extra is just to give a <em>little</em> weighting to terms that appear in all documents. Generally a +1 is simply added.</p><p>After that, I also log if there is a partial match for more than 1 of the search terms. Since we stored which terms came after each term in the document, we can easily check if the next word in our search term matches against any of those. If so, then we add to our partial match coefficient. Finally, when all of the weights are added together, we multiply the weights added together with a simply <code>1 + log(p + 1)</code> where p is our partial coefficient, or rather how many terms we found that match the same order as the search query.</p><p>Pseudo-code for this may look like this:</p><pre><code>find(text) {
    words = tokenise(text)
    foreach(words as word) {
        foreach(terms[word].documents as document_id -&gt; document_weight) {
            results[document] += terms[word].idf * document_weight // set the score for this document and store in the results
        }
    } 
}
</code></pre><h3 id="forthosewhowantarealexample">For those who want a real example</h3><p>Yes, yes, I apologise for simply using pseudocode. I guess I wanted to make this a universal summary of how full-text search engines work. However, I have a Javascript version on Gist which should work: <a href="https://gist.github.com/modamodamoda/1cd0c473336ab6a1f5e4c39233152f63">click here</a>. Note that in this version, I calculate idf at runtime, when the find algorithm is used. I am currently using this search engine for one of my static-website blogs.</p></div></div></div></div><footer class="container"><div id="contact"><h2>Contact</h2><form id="ms" method="POST"><input type="hidden" name="name" value="User" /><input type="hidden" name="l" value="https://jackpenny.com/" /><p><input name="email" type="text" placeholder="Your E-Mail" /></p><p><textarea name="summary" placeholder="Your Message"></textarea></p><p><button type="submit" class="submit">Submit Message</button></p></form></div></footer></body></html>